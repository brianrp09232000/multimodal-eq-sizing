{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5549253,"sourceType":"datasetVersion","datasetId":2976522},{"sourceId":13920741,"sourceType":"datasetVersion","datasetId":8870532},{"sourceId":13965676,"sourceType":"datasetVersion","datasetId":8902694}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\nGITHUB_EMAIL = \"brianrp09232000@gmail.com\"  # Replace with your actual git email if different\nGITHUB_USERNAME = \"brianrp09232000\"\nREPO_NAME = \"multimodal-eq-sizing\"\nBRANCH_NAME = \"feature/ticket-16-leg-1\"\n\ntry:\n    user_secrets = UserSecretsClient()\n    pat = user_secrets.get_secret(\"github_token\")\n    print(\"âœ… Token retrieved successfully.\")\nexcept Exception as e:\n    print(\"âŒ Error: Could not retrieve 'github_token' from Secrets.\")\n    print(\"Please go to Add-ons -> Secrets and add your token with the label 'github_token'.\")\n    raise e\n\nworking_dir = \"/kaggle/working\"\nrepo_path = os.path.join(working_dir, REPO_NAME)\n\nif os.path.exists(repo_path):\n    print(f\"ðŸ§¹ Removing existing repo at {repo_path}...\")\n    !rm -rf {repo_path}\n\nprint(f\"â¬‡ï¸ Cloning {REPO_NAME}...\")\nrepo_url = f\"https://{GITHUB_USERNAME}:{pat}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n!git clone {repo_url} {repo_path}\n\nprint(f\"twisted_rightwards_arrows Switching to branch: {BRANCH_NAME}...\")\n%cd {repo_path}\n!git fetch origin {BRANCH_NAME}\n!git checkout {BRANCH_NAME}\n\n!pip install -r requirements.txt\n\n!git config --global user.email \"{GITHUB_EMAIL}\"\n!git config --global user.name \"{GITHUB_USERNAME}\"\n\n%cd {working_dir}\nprint(\"âœ… Setup complete. You are now on branch:\", BRANCH_NAME)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n!rm -rf multimodal-eq-sizing\n!git clone https://github.com/brianrp09232000/multimodal-eq-sizing.git\n!pip install -r multimodal-eq-sizing/requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:16:37.387280Z","iopub.execute_input":"2025-12-07T04:16:37.387673Z","iopub.status.idle":"2025-12-07T04:16:47.764052Z","shell.execute_reply.started":"2025-12-07T04:16:37.387607Z","shell.execute_reply":"2025-12-07T04:16:47.762668Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'multimodal-eq-sizing'...\nremote: Enumerating objects: 829, done.\u001b[K\nremote: Counting objects: 100% (303/303), done.\u001b[K\nremote: Compressing objects: 100% (206/206), done.\u001b[K\nremote: Total 829 (delta 201), reused 114 (delta 97), pack-reused 526 (from 1)\u001b[K\nReceiving objects: 100% (829/829), 873.50 KiB | 13.44 MiB/s, done.\nResolving deltas: 100% (515/515), done.\nRequirement already satisfied: yfinance==0.2.66 in /usr/local/lib/python3.11/dist-packages (from -r multimodal-eq-sizing/requirements.txt (line 1)) (0.2.66)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r multimodal-eq-sizing/requirements.txt (line 2)) (2.2.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r multimodal-eq-sizing/requirements.txt (line 3)) (1.26.4)\nRequirement already satisfied: datetime in /usr/local/lib/python3.11/dist-packages (from -r multimodal-eq-sizing/requirements.txt (line 4)) (6.0)\nRequirement already satisfied: dataclasses in /usr/local/lib/python3.11/dist-packages (from -r multimodal-eq-sizing/requirements.txt (line 5)) (0.6)\nRequirement already satisfied: typing in /usr/local/lib/python3.11/dist-packages (from -r multimodal-eq-sizing/requirements.txt (line 6)) (3.7.4.3)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r multimodal-eq-sizing/requirements.txt (line 7)) (2.6.0+cu124)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r multimodal-eq-sizing/requirements.txt (line 8)) (4.53.3)\nRequirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.66->-r multimodal-eq-sizing/requirements.txt (line 1)) (2.32.5)\nRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.66->-r multimodal-eq-sizing/requirements.txt (line 1)) (0.0.12)\nRequirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.66->-r multimodal-eq-sizing/requirements.txt (line 1)) (4.5.0)\nRequirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.66->-r multimodal-eq-sizing/requirements.txt (line 1)) (2025.2)\nRequirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.66->-r multimodal-eq-sizing/requirements.txt (line 1)) (2.4.6)\nRequirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.66->-r multimodal-eq-sizing/requirements.txt (line 1)) (3.18.2)\nRequirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.66->-r multimodal-eq-sizing/requirements.txt (line 1)) (4.13.4)\nRequirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.66->-r multimodal-eq-sizing/requirements.txt (line 1)) (0.12.0)\nRequirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.66->-r multimodal-eq-sizing/requirements.txt (line 1)) (6.33.0)\nRequirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.66->-r multimodal-eq-sizing/requirements.txt (line 1)) (15.0.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r multimodal-eq-sizing/requirements.txt (line 2)) (2.9.0.post0)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r multimodal-eq-sizing/requirements.txt (line 2)) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->-r multimodal-eq-sizing/requirements.txt (line 3)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->-r multimodal-eq-sizing/requirements.txt (line 3)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->-r multimodal-eq-sizing/requirements.txt (line 3)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->-r multimodal-eq-sizing/requirements.txt (line 3)) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->-r multimodal-eq-sizing/requirements.txt (line 3)) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->-r multimodal-eq-sizing/requirements.txt (line 3)) (2.4.1)\nRequirement already satisfied: zope.interface in /usr/local/lib/python3.11/dist-packages (from datetime->-r multimodal-eq-sizing/requirements.txt (line 4)) (8.1.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r multimodal-eq-sizing/requirements.txt (line 7)) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r multimodal-eq-sizing/requirements.txt (line 7)) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r multimodal-eq-sizing/requirements.txt (line 7)) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r multimodal-eq-sizing/requirements.txt (line 7)) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r multimodal-eq-sizing/requirements.txt (line 7)) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r multimodal-eq-sizing/requirements.txt (line 7)) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r multimodal-eq-sizing/requirements.txt (line 7)) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r multimodal-eq-sizing/requirements.txt (line 7)) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->-r multimodal-eq-sizing/requirements.txt (line 7)) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->-r multimodal-eq-sizing/requirements.txt (line 7)) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->-r multimodal-eq-sizing/requirements.txt (line 7)) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->-r multimodal-eq-sizing/requirements.txt (line 7)) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->-r multimodal-eq-sizing/requirements.txt (line 7)) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->-r multimodal-eq-sizing/requirements.txt (line 7)) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r multimodal-eq-sizing/requirements.txt (line 7)) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r multimodal-eq-sizing/requirements.txt (line 7)) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r multimodal-eq-sizing/requirements.txt (line 7)) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r multimodal-eq-sizing/requirements.txt (line 7)) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r multimodal-eq-sizing/requirements.txt (line 7)) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r multimodal-eq-sizing/requirements.txt (line 7)) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r multimodal-eq-sizing/requirements.txt (line 7)) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers->-r multimodal-eq-sizing/requirements.txt (line 8)) (0.36.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers->-r multimodal-eq-sizing/requirements.txt (line 8)) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers->-r multimodal-eq-sizing/requirements.txt (line 8)) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->-r multimodal-eq-sizing/requirements.txt (line 8)) (2025.11.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->-r multimodal-eq-sizing/requirements.txt (line 8)) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->-r multimodal-eq-sizing/requirements.txt (line 8)) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers->-r multimodal-eq-sizing/requirements.txt (line 8)) (4.67.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance==0.2.66->-r multimodal-eq-sizing/requirements.txt (line 1)) (2.7)\nRequirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance==0.2.66->-r multimodal-eq-sizing/requirements.txt (line 1)) (2.0.0)\nRequirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance==0.2.66->-r multimodal-eq-sizing/requirements.txt (line 1)) (2025.10.5)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers->-r multimodal-eq-sizing/requirements.txt (line 8)) (1.2.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->-r multimodal-eq-sizing/requirements.txt (line 2)) (1.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance==0.2.66->-r multimodal-eq-sizing/requirements.txt (line 1)) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance==0.2.66->-r multimodal-eq-sizing/requirements.txt (line 1)) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance==0.2.66->-r multimodal-eq-sizing/requirements.txt (line 1)) (2.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r multimodal-eq-sizing/requirements.txt (line 7)) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->-r multimodal-eq-sizing/requirements.txt (line 3)) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->-r multimodal-eq-sizing/requirements.txt (line 3)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->-r multimodal-eq-sizing/requirements.txt (line 3)) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->-r multimodal-eq-sizing/requirements.txt (line 3)) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->-r multimodal-eq-sizing/requirements.txt (line 3)) (2024.2.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance==0.2.66->-r multimodal-eq-sizing/requirements.txt (line 1)) (2.23)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->-r multimodal-eq-sizing/requirements.txt (line 3)) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import sys\nimport pathlib\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:16:47.766163Z","iopub.execute_input":"2025-12-07T04:16:47.767592Z","iopub.status.idle":"2025-12-07T04:16:48.819409Z","shell.execute_reply.started":"2025-12-07T04:16:47.767480Z","shell.execute_reply":"2025-12-07T04:16:48.811441Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"np.seterr(invalid=\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:16:48.822469Z","iopub.execute_input":"2025-12-07T04:16:48.823612Z","iopub.status.idle":"2025-12-07T04:16:48.835895Z","shell.execute_reply.started":"2025-12-07T04:16:48.823577Z","shell.execute_reply":"2025-12-07T04:16:48.833332Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Uses the current directory where the notebook is running\nrepo_root = pathlib.Path(\"multimodal-eq-sizing\")\nsys.path.append(str(repo_root.resolve())) # .resolve() gets the full absolute path locally","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:16:48.838379Z","iopub.execute_input":"2025-12-07T04:16:48.838659Z","iopub.status.idle":"2025-12-07T04:16:48.858500Z","shell.execute_reply.started":"2025-12-07T04:16:48.838637Z","shell.execute_reply":"2025-12-07T04:16:48.853094Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from src.data.loaders import (\n    get_tickers_history,\n    get_return_data,\n    get_excess_return,\n    get_vix_data,\n    get_spread_z,\n    get_sector_map,\n    get_adv_dollar\n)\n\nfrom src.data.features.price_features import calculate_leg_one_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:16:48.860704Z","iopub.execute_input":"2025-12-07T04:16:48.861056Z","iopub.status.idle":"2025-12-07T04:17:05.128697Z","shell.execute_reply.started":"2025-12-07T04:16:48.861030Z","shell.execute_reply":"2025-12-07T04:17:05.127785Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from src.data.universe import tickers_with_most_headlines","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:17:05.129676Z","iopub.execute_input":"2025-12-07T04:17:05.130242Z","iopub.status.idle":"2025-12-07T04:17:23.930985Z","shell.execute_reply.started":"2025-12-07T04:17:05.130190Z","shell.execute_reply":"2025-12-07T04:17:23.930099Z"}},"outputs":[{"name":"stderr","text":"2025-12-07 04:17:07.402252: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765081027.631508     181 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765081027.699034     181 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":6},{"cell_type":"code","source":"import os\n\n# This will print all the folders in the input directory\nprint(os.listdir(\"/kaggle/input\"))\n\n# Once you see the folder name above, replace 'YOUR_FOLDER_NAME' below to see the files inside\n# print(os.listdir(\"/kaggle/input/YOUR_FOLDER_NAME\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:17:23.931897Z","iopub.execute_input":"2025-12-07T04:17:23.932604Z","iopub.status.idle":"2025-12-07T04:17:23.938864Z","shell.execute_reply.started":"2025-12-07T04:17:23.932570Z","shell.execute_reply":"2025-12-07T04:17:23.937812Z"}},"outputs":[{"name":"stdout","text":"['news-trading', 'nasdaq-news', 'financial-news']\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"filename = \"/kaggle/input/nasdaq-news/nasdaq_news.csv\"\n\nnews_df = pd.read_csv(filename)\n\n# 1. Check Local (Git/PC) first\nif os.path.exists(filename):\n    news_df = pd.read_csv(filename)\n    print(f\"Success: Loaded {filename} from local folder.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:17:50.105047Z","iopub.execute_input":"2025-12-07T04:17:50.105906Z","iopub.status.idle":"2025-12-07T04:24:14.851495Z","shell.execute_reply.started":"2025-12-07T04:17:50.105863Z","shell.execute_reply":"2025-12-07T04:24:14.850393Z"}},"outputs":[{"name":"stdout","text":"Success: Loaded /kaggle/input/nasdaq-news/nasdaq_news.csv from local folder.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def count_headlines_per_ticker(news_df, start=None, end=None):\n    \"\"\"Counts the number of headlines for each ticker symbol \n    Input: news_df pandas dataframe with ticker column for ticker symbols\n    Output: pandas dataframe containing two columns: ticker names and the \n                number of headlines for the ticker\"\"\"\n    \n    #check columns in dataframe\n    columns = list(news_df.columns)\n    if (('date' not in columns) and ('Date' not in columns)) or (('ticker' not in columns) and ('Stock_symbol' not in columns)):\n        print('input dataframe does not have both ticker and date columns')\n        return pd.DataFrame()\n    \n    #find column names\n    date_col = 'date' if 'date' in columns else 'Date'\n    ticker_col = 'ticker' if 'ticker' in columns else 'Stock_symbol'\n\n    #filter dates\n    if start is not None: \n        start_filter = news_df[date_col] >= str(start)\n        news_df = news_df[start_filter]\n    if end is not None: \n        end_filter = news_df[date_col] <= str(end)\n        news_df = news_df[end_filter]\n    \n    # Count occurrences in a specific column\n    headline_counts = news_df[ticker_col].value_counts()\n    df = headline_counts.to_frame(name='count')\n    df['ticker'] = list(df.index)\n    df = df.reset_index(drop=True)\n    \n    return df[['ticker','count']]\n\n\n\ndef tickers_with_most_headlines(news_df, start=None, end=None, n=200):\n    \"\"\"Finds the tickers with the most headlines \n    Input: news_df pandas dataframe with ticker column for ticker symbols\n            optional: n interger, number of top tickers to return\n    Output: list containing the number of headlines per ticker\n                for the tickers with the most headlines\"\"\"\n    \n    #count headlines for each ticker\n    df = count_headlines_per_ticker(news_df, start, end)\n\n    #limit dataframe to n tickers\n    df = df.sort_values(['count'], ascending=False)\n    df = df[:n]\n    df.reset_index(drop=True, inplace=True)\n    \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:36:25.486028Z","iopub.execute_input":"2025-12-07T04:36:25.486450Z","iopub.status.idle":"2025-12-07T04:36:25.499029Z","shell.execute_reply.started":"2025-12-07T04:36:25.486422Z","shell.execute_reply":"2025-12-07T04:36:25.497826Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"start = pd.Timestamp('2010-01-04 05:00:00+0000', tz='UTC')\nend   = pd.Timestamp('2018-12-28 05:00:00+0000', tz='UTC')\n\n#limit news to start and stop times\nnews_df['Date'] = pd.to_datetime(list(news_df['Date']), utc=True)\nnews_df = news_df[news_df['Date'] >= start]\nnews_df = news_df[news_df['Date'] <= end]\n\ntickers = tickers_with_most_headlines(news_df, str(start), str(end), 300)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:36:32.698492Z","iopub.execute_input":"2025-12-07T04:36:32.698927Z","iopub.status.idle":"2025-12-07T04:36:40.627863Z","shell.execute_reply.started":"2025-12-07T04:36:32.698899Z","shell.execute_reply":"2025-12-07T04:36:40.626797Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"#get yfinance ticker history for all tickers in tickers df\n#yfinance will produce the \"possibly delisted\" message for tickers without information\ndf = get_tickers_history(list(tickers['ticker']), start=start, end=end)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:47:42.221988Z","iopub.execute_input":"2025-12-07T04:47:42.222444Z","iopub.status.idle":"2025-12-07T04:48:30.004971Z","shell.execute_reply.started":"2025-12-07T04:47:42.222413Z","shell.execute_reply":"2025-12-07T04:48:30.003837Z"}},"outputs":[{"name":"stderr","text":"ERROR:yfinance:$X: possibly delisted; no timezone found\nERROR:yfinance:$DISH: possibly delisted; no timezone found\nERROR:yfinance:$WBA: possibly delisted; no timezone found\nERROR:yfinance:$FL: possibly delisted; no timezone found\nERROR:yfinance:$SPWR: possibly delisted; no price data found  (1d 2010-01-04 05:00:00+00:00 -> 2018-12-29 05:00:00+00:00) (Yahoo error = \"Data doesn't exist for startDate = 1262581200, endDate = 1546059600\")\nERROR:yfinance:$BRK: possibly delisted; no price data found  (1d 2010-01-04 05:00:00+00:00 -> 2018-12-29 05:00:00+00:00)\nERROR:yfinance:$DFS: possibly delisted; no timezone found\nERROR:yfinance:$PXD: possibly delisted; no timezone found\nERROR:yfinance:$AI: possibly delisted; no price data found  (1d 2010-01-04 05:00:00+00:00 -> 2018-12-29 05:00:00+00:00) (Yahoo error = \"Data doesn't exist for startDate = 1262581200, endDate = 1546059600\")\nERROR:yfinance:$MRO: possibly delisted; no timezone found\nERROR:yfinance:$AMTD: possibly delisted; no price data found  (1d 2010-01-04 05:00:00+00:00 -> 2018-12-29 05:00:00+00:00) (Yahoo error = \"Data doesn't exist for startDate = 1262581200, endDate = 1546059600\")\nERROR:yfinance:$BIG: possibly delisted; no timezone found\nERROR:yfinance:$HES: possibly delisted; no timezone found\nERROR:yfinance:$HA: possibly delisted; no timezone found\nERROR:yfinance:$CONN: possibly delisted; no price data found  (1d 2010-01-04 05:00:00+00:00 -> 2018-12-29 05:00:00+00:00)\nERROR:yfinance:$SWN: possibly delisted; no timezone found\n/kaggle/working/multimodal-eq-sizing/src/data/loaders.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n  return pd.concat(tickers_history_dfs)\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"#remove unnecessary columns\ndf = df.drop(['Capital Gains','Adj Close'], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:48:30.032463Z","iopub.execute_input":"2025-12-07T04:48:30.033505Z","iopub.status.idle":"2025-12-07T04:48:30.073755Z","shell.execute_reply.started":"2025-12-07T04:48:30.033471Z","shell.execute_reply":"2025-12-07T04:48:30.072803Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"def add_sector(df):\n    tickers = df[\"ticker\"].unique()\n    sector_map = get_sector_map(tickers)\n    df = df.join(sector_map, on=\"ticker\")\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:48:30.075829Z","iopub.execute_input":"2025-12-07T04:48:30.076174Z","iopub.status.idle":"2025-12-07T04:48:30.081455Z","shell.execute_reply.started":"2025-12-07T04:48:30.076149Z","shell.execute_reply":"2025-12-07T04:48:30.080400Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"df = add_sector(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:48:30.083551Z","iopub.execute_input":"2025-12-07T04:48:30.084092Z","iopub.status.idle":"2025-12-07T04:49:54.074894Z","shell.execute_reply.started":"2025-12-07T04:48:30.084066Z","shell.execute_reply":"2025-12-07T04:49:54.073751Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"# remove None values in 'sector', these are ETFs not stocks\ndf = df.dropna(subset=['sector'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:49:54.076381Z","iopub.execute_input":"2025-12-07T04:49:54.076674Z","iopub.status.idle":"2025-12-07T04:49:54.173526Z","shell.execute_reply.started":"2025-12-07T04:49:54.076653Z","shell.execute_reply":"2025-12-07T04:49:54.172618Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"#limit df to only 200 tickers and tickers with data\nkeep_tickers = list(df['ticker'].drop_duplicates()[:200])\ndf = df[df['ticker'].isin(keep_tickers)]\ntickers = tickers[tickers['ticker'].isin(keep_tickers)]\n\nleg_one_inds = calculate_leg_one_features(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:49:54.176600Z","iopub.execute_input":"2025-12-07T04:49:54.176901Z","iopub.status.idle":"2025-12-07T04:49:56.422778Z","shell.execute_reply.started":"2025-12-07T04:49:54.176870Z","shell.execute_reply":"2025-12-07T04:49:56.420651Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"def get_date_range(df: pd.DataFrame) -> tuple:\n    grouped_by_date = df.groupby([\"ticker\"]).agg(['min', 'max', 'count'])[\"Date\"]\n    start = grouped_by_date[\"min\"].min()\n    end = grouped_by_date[\"max\"].max()\n    return start, end","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:49:56.427125Z","iopub.execute_input":"2025-12-07T04:49:56.427709Z","iopub.status.idle":"2025-12-07T04:49:56.438340Z","shell.execute_reply.started":"2025-12-07T04:49:56.427670Z","shell.execute_reply":"2025-12-07T04:49:56.436517Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"def add_excess_return(df, start, end):\n    excess_return_df = get_excess_return(df, start, end)\n    df = df.merge(excess_return_df, on=[\"ticker\", \"Date\"], how=\"left\")\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:49:56.439730Z","iopub.execute_input":"2025-12-07T04:49:56.440202Z","iopub.status.idle":"2025-12-07T04:49:56.463100Z","shell.execute_reply.started":"2025-12-07T04:49:56.440164Z","shell.execute_reply":"2025-12-07T04:49:56.460910Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"df = add_excess_return(df, start, end)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:49:56.465321Z","iopub.execute_input":"2025-12-07T04:49:56.466065Z","iopub.status.idle":"2025-12-07T04:49:57.177340Z","shell.execute_reply.started":"2025-12-07T04:49:56.466016Z","shell.execute_reply":"2025-12-07T04:49:57.175511Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"def add_vix_z(df, start, end):\n    vix_z_df = get_vix_data(start, end)\n    format_str = \"%Y-%m-%d\"\n    vix_z_df[\"Date\"] = vix_z_df[\"Date\"].dt.strftime(format_str)\n    df[\"Date\"] = df[\"Date\"].dt.strftime(format_str) \n    df = df.merge(vix_z_df, on=[\"Date\"], how=\"left\")\n    df['Date'] = pd.to_datetime(df['Date'], utc=True)\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:49:57.184335Z","iopub.execute_input":"2025-12-07T04:49:57.184897Z","iopub.status.idle":"2025-12-07T04:49:57.195671Z","shell.execute_reply.started":"2025-12-07T04:49:57.184869Z","shell.execute_reply":"2025-12-07T04:49:57.193800Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"df = add_vix_z(df, start, end)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:49:57.197434Z","iopub.execute_input":"2025-12-07T04:49:57.197848Z","iopub.status.idle":"2025-12-07T04:50:02.161212Z","shell.execute_reply.started":"2025-12-07T04:49:57.197812Z","shell.execute_reply":"2025-12-07T04:50:02.159831Z"}},"outputs":[{"name":"stdout","text":"Yay!ðŸ¥³\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"def add_spread_z(existing_df: pd.DataFrame, buffer_days=380) -> pd.DataFrame:\n    \"\"\"\n    Use existing OHLCV df, pull buffered history, compute young-safe spread_z on the combined\n    Then merge back only the target window rows to prevent nulls.\n    \"\"\"\n    df = existing_df.copy()\n    start, end = df[\"Date\"].min(), df[\"Date\"].max()\n\n    tickers = sorted(df['ticker'].unique())\n    fetch_start = start - timedelta(days=buffer_days)\n    fetch_end   = end\n\n    # You already have get_tickers_history(tickers, start, end)\n    hist = get_tickers_history(tickers, fetch_start, fetch_end)\n    hist[\"Date\"] = pd.to_datetime(hist[\"Date\"], utc=True)\n\n    # Combine buffer + existing; keep existing rows on overlap\n    combined = pd.concat([hist, df], ignore_index=True)\n    combined = combined.sort_values(['ticker', \"Date\"])\n    combined = combined.drop_duplicates(subset=['ticker', \"Date\"], keep=\"last\")\n\n    # Compute young-safe spread_z on the full combined range\n    combined = get_spread_z(combined)\n\n    # Merge only computed columns back to target window\n    cols_to_merge = ['ticker', 'Date', \"spread_z\"]\n    out = df.merge(combined[cols_to_merge], on=['ticker', 'Date'], how=\"left\")\n\n    # Final minimal, causal clean-up to guarantee NON-NULL spread_z in target window:\n    # 1) per-ticker forward-fill (past only), 2) same-day cross-section median, 3) final 0\n    out[\"spread_z\"] = (\n        out.groupby('ticker')[\"spread_z\"].ffill()\n           .fillna(out.groupby('Date')[\"spread_z\"].transform(\"median\"))\n           .fillna(0.0)\n    ).clip(-3, 3)\n\n    return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:50:02.162791Z","iopub.execute_input":"2025-12-07T04:50:02.163067Z","iopub.status.idle":"2025-12-07T04:50:02.173677Z","shell.execute_reply.started":"2025-12-07T04:50:02.163047Z","shell.execute_reply":"2025-12-07T04:50:02.172523Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"df = add_spread_z(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:50:02.174942Z","iopub.execute_input":"2025-12-07T04:50:02.175466Z","iopub.status.idle":"2025-12-07T04:50:40.948822Z","shell.execute_reply.started":"2025-12-07T04:50:02.175418Z","shell.execute_reply":"2025-12-07T04:50:40.947704Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"def add_adv_dollar(df):\n    adv_df = get_adv_dollar(df)\n    \n    df = df.merge(\n        adv_df,\n        on=[\"Date\", \"ticker\"],\n        how=\"left\",\n    )\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:50:40.950259Z","iopub.execute_input":"2025-12-07T04:50:40.950739Z","iopub.status.idle":"2025-12-07T04:50:40.956378Z","shell.execute_reply.started":"2025-12-07T04:50:40.950708Z","shell.execute_reply":"2025-12-07T04:50:40.955285Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"df = add_adv_dollar(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:50:40.957452Z","iopub.execute_input":"2025-12-07T04:50:40.957802Z","iopub.status.idle":"2025-12-07T04:50:41.628610Z","shell.execute_reply.started":"2025-12-07T04:50:40.957773Z","shell.execute_reply":"2025-12-07T04:50:41.627374Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"# Change Date formats to UTCdf['Date'] = pd.to_datetime(df['Date'], utc=True).dt.normalize()\nleg_one_inds['Date'] = pd.to_datetime(leg_one_inds['Date'], utc=True).dt.normalize()\n\n# Select only the new features\njoin_keys = ['ticker', 'Date']\nnew_features = [col for col in leg_one_inds.columns if col not in df.columns or col in join_keys]\nleg_one_clean = leg_one_inds[new_features].copy()\n\n# Remove duplicate rows in the indicators\nleg_one_clean = leg_one_clean.drop_duplicates(subset=join_keys)\n\n# Merge\ndf = df.merge(\n    leg_one_clean, \n    on=join_keys, \n    how='left'\n)\n\n# Verification\nprint(f\"New shape: {df.shape}\")\nprint(\"New columns added:\", list(set(df.columns) - set(leg_one_inds.columns).symmetric_difference(set(new_features))))\n# (Simple print of added columns for sanity check)\nprint(\"Added Columns:\", [c for c in new_features if c not in join_keys])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:50:41.630538Z","iopub.execute_input":"2025-12-07T04:50:41.630943Z","iopub.status.idle":"2025-12-07T04:50:42.084745Z","shell.execute_reply.started":"2025-12-07T04:50:41.630912Z","shell.execute_reply":"2025-12-07T04:50:42.083662Z"}},"outputs":[{"name":"stdout","text":"New shape: (437217, 26)\nNew columns added: ['r1', 'VIX_z', 'o2c_return', 'spread_z', 'vol_realized_20d', 'ticker', 'VIX_Close', 'mom_12_1', 'mom_rank', 'r10', 'vol_parkinson_20d', 'r5', 'adv_dollar', 'spy_r1', 'Date', 'dollar_volume', 'trend_ema_diff', 'excess_return']\nAdded Columns: ['r1', 'r5', 'r10', 'trend_ema_diff', 'vol_realized_20d', 'vol_parkinson_20d', 'mom_12_1', 'mom_rank', 'spy_r1']\n","output_type":"stream"}],"execution_count":83},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\n\npd.set_option('display.max_colwidth', None)\n\npd.set_option('display.max_rows', 100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:50:42.085928Z","iopub.execute_input":"2025-12-07T04:50:42.086300Z","iopub.status.idle":"2025-12-07T04:50:42.092081Z","shell.execute_reply.started":"2025-12-07T04:50:42.086272Z","shell.execute_reply":"2025-12-07T04:50:42.090723Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"df[\"next_day_excess_return\"] = df.groupby('ticker')['excess_return'].shift(-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:50:42.093251Z","iopub.execute_input":"2025-12-07T04:50:42.093604Z","iopub.status.idle":"2025-12-07T04:50:42.152360Z","shell.execute_reply.started":"2025-12-07T04:50:42.093573Z","shell.execute_reply":"2025-12-07T04:50:42.151440Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"df['split'] = 'train'\ndf.loc[df['Date'] >=\"2015-01-01\", \"split\"] = \"val\"\ndf.loc[df['Date'] >= \"2017-01-01\", \"split\"] = 'test'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:50:42.153543Z","iopub.execute_input":"2025-12-07T04:50:42.153884Z","iopub.status.idle":"2025-12-07T04:50:42.189345Z","shell.execute_reply.started":"2025-12-07T04:50:42.153856Z","shell.execute_reply":"2025-12-07T04:50:42.188217Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"def count_headlines_all_days(news_df):\n    \"\"\"Counts the number of headlines for each ticker symbol each day\n    Input: news_df pandas dataframe with ticker column for ticker symbols and date for the headline date\n    Output: pandas dataframe containing the number of headlines per ticker per day\n                indexes are dates in string and tickers as the column names\"\"\"\n    \n    #check columns in dataframe\n    columns = list(news_df.columns)\n    if (('date' not in columns) and ('Date' not in columns)) or (('ticker' not in columns) and ('Stock_symbol' not in columns)):\n        print('input dataframe does not have both ticker and date columns')\n        return pd.DataFrame()\n    \n    #find column names\n    date_col = 'date' if 'date' in columns else 'Date'\n    ticker_col = 'ticker' if 'ticker' in columns else 'Stock_symbol'\n    \n    # Count occurrences in the date column\n    headline_dates = news_df[date_col]#.str[:10]#.value_counts()\n    df = pd.DataFrame({ticker_col: news_df[ticker_col],\n                       date_col: headline_dates})\n    \n    # count headlines per day per ticker\n    df = df.groupby([date_col, ticker_col]).size().unstack(fill_value=0)\n    \n    #create list of dates needed\n    format_code = \"%Y-%m-%d\"# Corresponds to 'YYYY-MM-DD'\n    set_of_dates = set(df.index)\n    date_min = start#datetime.strptime(min('2010-01-04',min(set_of_dates)), format_code).date() #datetime(2000,1,1).date()#\n    date_max = end #datetime.strptime(max('2018-12-28',max(set_of_dates)), format_code).date()\n    date_lst = [(date_min+timedelta(i)) for i in range(int((date_max-date_min).days)+1)]\n    \n    #find dates not in dataframe\n    missing_dates = dict([(day,int(0)) for day in set(date_lst).difference(set(df.index))])\n    \n    #add missing dates to dataframe\n    tickers = list(set(df.columns))\n    tickers.sort()\n    empty_dict = dict([(ticker, missing_dates) for ticker in tickers])\n    add_dates = pd.DataFrame(empty_dict)\n    df = pd.concat([df, add_dates], ignore_index=False)\n    \n    #sort rows and columns\n    df = df.sort_index()\n    df = df.T\n    df = df.sort_index()\n    \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:50:42.191750Z","iopub.execute_input":"2025-12-07T04:50:42.192052Z","iopub.status.idle":"2025-12-07T04:50:42.203157Z","shell.execute_reply.started":"2025-12-07T04:50:42.192029Z","shell.execute_reply":"2025-12-07T04:50:42.201657Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"#from src.data.features.news_features import count_headlines_all_days\n\n\ndef add_news_flag(news_df, price_df):\n    \"\"\"adds a new news flag column: 0=no news, 1=news\n    input: news_df with 'date', 'ticker', and other columns\n            price_df with 'Date', 'ticker', and other columns\n            optional start and end Timestamps\n    output: dataframe df\n    \"\"\"\n\n    #count headlines per ticker per day\n    news_count = count_headlines_all_days(news_df)\n    \n    #filter count_df by date\n    news_count = news_count.T\n    news_count['date'] = pd.to_datetime(list(news_count.index), utc=True)\n    \n    #convert news_count df to different format\n    news_cols = list(news_count.columns)\n    news_count = news_count.melt(id_vars=['date'], value_vars=news_cols, \n                  var_name='ticker', value_name='news flag')\n\n    # change count to flag: 0=no news, 1=news\n    news_count['news flag'] = [flag if flag < 2 else 1 for flag in news_count['news flag']]\n    news_count['date'] = pd.to_datetime(news_count['date'], utc=True)\n    news_count.sort_values(['date','ticker'], inplace=True)\n    \n    #add news flag: 0=no news, 1=news\n    price_df = pd.merge(price_df, news_count, left_on=['Date','ticker'], \n              right_on=['date','ticker'])\n\n    return price_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:50:42.204354Z","iopub.execute_input":"2025-12-07T04:50:42.204721Z","iopub.status.idle":"2025-12-07T04:50:42.224001Z","shell.execute_reply.started":"2025-12-07T04:50:42.204696Z","shell.execute_reply":"2025-12-07T04:50:42.223060Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"df = add_news_flag(news_df, df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:50:42.225019Z","iopub.execute_input":"2025-12-07T04:50:42.225306Z","iopub.status.idle":"2025-12-07T04:53:02.247543Z","shell.execute_reply.started":"2025-12-07T04:50:42.225280Z","shell.execute_reply":"2025-12-07T04:53:02.246438Z"}},"outputs":[],"execution_count":89},{"cell_type":"code","source":"df.to_csv('final_dataset.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:53:02.249522Z","iopub.execute_input":"2025-12-07T04:53:02.249839Z","iopub.status.idle":"2025-12-07T04:53:26.622493Z","shell.execute_reply.started":"2025-12-07T04:53:02.249814Z","shell.execute_reply":"2025-12-07T04:53:26.621418Z"}},"outputs":[],"execution_count":90},{"cell_type":"code","source":"tickers.to_csv('top_tickers.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:53:26.624336Z","iopub.execute_input":"2025-12-07T04:53:26.624618Z","iopub.status.idle":"2025-12-07T04:53:26.631534Z","shell.execute_reply.started":"2025-12-07T04:53:26.624598Z","shell.execute_reply":"2025-12-07T04:53:26.630518Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"get_return_data(\"/kaggle/working/final_dataset.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T04:53:26.632876Z","iopub.execute_input":"2025-12-07T04:53:26.633137Z","iopub.status.idle":"2025-12-07T04:53:32.485572Z","shell.execute_reply.started":"2025-12-07T04:53:26.633118Z","shell.execute_reply":"2025-12-07T04:53:32.484597Z"}},"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"                            Date       Open       High        Low      Close  \\\n0      2010-01-05 00:00:00+00:00  53.698786  54.428203  53.664055  53.941925   \n1      2010-01-06 00:00:00+00:00  53.941917  54.254524  53.629311  53.664047   \n2      2010-01-07 00:00:00+00:00  53.768263  57.241669  53.594597  56.442783   \n3      2010-01-08 00:00:00+00:00  56.651195  57.971085  56.512255  57.658478   \n4      2010-01-11 00:00:00+00:00  58.457350  58.631016  57.450062  58.214211   \n...                          ...        ...        ...        ...        ...   \n437028 2018-12-21 00:00:00+00:00  18.687380  18.954125  18.176754  18.245346   \n437029 2018-12-24 00:00:00+00:00  18.169136  18.435881  17.993847  18.009089   \n437030 2018-12-26 00:00:00+00:00  18.108161  18.961744  18.001464  18.931259   \n437031 2018-12-27 00:00:00+00:00  18.733111  19.152281  18.473987  19.144661   \n437032 2018-12-28 00:00:00+00:00  19.281840  19.426644  19.045580  19.228491   \n\n            Volume  Dividends  Stock Splits ticker             sector  \\\n0       13469263.0        0.0           0.0     GE        Industrials   \n1       11573422.0        0.0           0.0     GE        Industrials   \n2       38701038.0        0.0           0.0     GE        Industrials   \n3       24019636.0        0.0           0.0     GE        Industrials   \n4       15999249.0        0.0           0.0     GE        Industrials   \n...            ...        ...           ...    ...                ...   \n437028   4434600.0        0.0           0.0    HRB  Consumer Cyclical   \n437029   1678100.0        0.0           0.0    HRB  Consumer Cyclical   \n437030   3066300.0        0.0           0.0    HRB  Consumer Cyclical   \n437031   3214400.0        0.0           0.0    HRB  Consumer Cyclical   \n437032   2151300.0        0.0           0.0    HRB  Consumer Cyclical   \n\n        o2c_return  excess_return  VIX_Close     VIX_z  spread_z  \\\n0         0.004528       0.001261  19.350000 -1.314181  0.859574   \n1        -0.005151      -0.006825  19.160000 -1.323599  1.393723   \n2         0.049742       0.043662  19.059999 -1.324017  0.008607   \n3         0.017780       0.011810  18.129999 -1.413993 -0.564963   \n4        -0.004159      -0.001118  17.549999 -1.465035  0.600918   \n...            ...            ...        ...       ...       ...   \n437028   -0.023654       0.000825  30.110001  2.909232 -1.809320   \n437029   -0.008809       0.010853  36.070000  3.000000 -2.102018   \n437030    0.045455       0.002186  30.410000  2.812017 -1.569047   \n437031    0.021969      -0.000705  29.959999  2.675121 -2.376681   \n437032   -0.002767       0.004566  28.340000  2.320699 -2.264180   \n\n        dollar_volume    adv_dollar        r1        r5       r10  \\\n0        7.265580e+08           NaN  0.005178       NaN       NaN   \n1        6.210767e+08           NaN -0.005151       NaN       NaN   \n2        2.184394e+09           NaN  0.051780       NaN       NaN   \n3        1.384936e+09           NaN  0.021539       NaN       NaN   \n4        9.313836e+08           NaN  0.009638  0.084790       NaN   \n...               ...           ...       ...       ...       ...   \n437028   8.091081e+07  7.369267e+07 -0.023654 -0.112676 -0.114645   \n437029   3.022105e+07  7.425269e+07 -0.012949 -0.099123 -0.152439   \n437030   5.804892e+07  7.482717e+07  0.051206 -0.045350 -0.105188   \n437031   6.153860e+07  7.509515e+07  0.011272  0.000797 -0.104137   \n437032   4.136625e+07  7.377027e+07  0.004379  0.028956 -0.066593   \n\n        trend_ema_diff  vol_realized_20d  vol_parkinson_20d  mom_12_1  \\\n0             0.032596               NaN                NaN       NaN   \n1             0.024566               NaN                NaN       NaN   \n2             0.344084               NaN                NaN       NaN   \n3             0.727209               NaN                NaN       NaN   \n4             1.077109               NaN                NaN       NaN   \n...                ...               ...                ...       ...   \n437028       -0.642881          0.021191           0.021804  0.024889   \n437029       -0.800662          0.020986           0.021909  0.070188   \n437030       -0.803862          0.024706           0.022873  0.096820   \n437031       -0.771849          0.024960           0.023275  0.107925   \n437032       -0.728459          0.024501           0.023244  0.081471   \n\n        mom_rank    spy_r1  next_day_excess_return  split  \\\n0            NaN  0.002647               -0.006825  train   \n1            NaN  0.000704                0.043662  train   \n2            NaN  0.004221                0.011810  train   \n3            NaN  0.003328               -0.001118  train   \n4            NaN  0.001397                0.014180  train   \n...          ...       ...                     ...    ...   \n437028     0.585 -0.020489                0.010853   test   \n437029     0.640 -0.026423                0.002186   test   \n437030     0.695  0.050525               -0.000705   test   \n437031     0.700  0.007677                0.004566   test   \n437032     0.645 -0.001290                     NaN   test   \n\n                             date  news flag  \n0       2010-01-05 00:00:00+00:00          0  \n1       2010-01-06 00:00:00+00:00          0  \n2       2010-01-07 00:00:00+00:00          0  \n3       2010-01-08 00:00:00+00:00          0  \n4       2010-01-11 00:00:00+00:00          0  \n...                           ...        ...  \n437028  2018-12-21 00:00:00+00:00          1  \n437029  2018-12-24 00:00:00+00:00          0  \n437030  2018-12-26 00:00:00+00:00          0  \n437031  2018-12-27 00:00:00+00:00          0  \n437032  2018-12-28 00:00:00+00:00          0  \n\n[437033 rows x 30 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n      <th>Dividends</th>\n      <th>Stock Splits</th>\n      <th>ticker</th>\n      <th>sector</th>\n      <th>o2c_return</th>\n      <th>excess_return</th>\n      <th>VIX_Close</th>\n      <th>VIX_z</th>\n      <th>spread_z</th>\n      <th>dollar_volume</th>\n      <th>adv_dollar</th>\n      <th>r1</th>\n      <th>r5</th>\n      <th>r10</th>\n      <th>trend_ema_diff</th>\n      <th>vol_realized_20d</th>\n      <th>vol_parkinson_20d</th>\n      <th>mom_12_1</th>\n      <th>mom_rank</th>\n      <th>spy_r1</th>\n      <th>next_day_excess_return</th>\n      <th>split</th>\n      <th>date</th>\n      <th>news flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2010-01-05 00:00:00+00:00</td>\n      <td>53.698786</td>\n      <td>54.428203</td>\n      <td>53.664055</td>\n      <td>53.941925</td>\n      <td>13469263.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>GE</td>\n      <td>Industrials</td>\n      <td>0.004528</td>\n      <td>0.001261</td>\n      <td>19.350000</td>\n      <td>-1.314181</td>\n      <td>0.859574</td>\n      <td>7.265580e+08</td>\n      <td>NaN</td>\n      <td>0.005178</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.032596</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.002647</td>\n      <td>-0.006825</td>\n      <td>train</td>\n      <td>2010-01-05 00:00:00+00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010-01-06 00:00:00+00:00</td>\n      <td>53.941917</td>\n      <td>54.254524</td>\n      <td>53.629311</td>\n      <td>53.664047</td>\n      <td>11573422.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>GE</td>\n      <td>Industrials</td>\n      <td>-0.005151</td>\n      <td>-0.006825</td>\n      <td>19.160000</td>\n      <td>-1.323599</td>\n      <td>1.393723</td>\n      <td>6.210767e+08</td>\n      <td>NaN</td>\n      <td>-0.005151</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.024566</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000704</td>\n      <td>0.043662</td>\n      <td>train</td>\n      <td>2010-01-06 00:00:00+00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2010-01-07 00:00:00+00:00</td>\n      <td>53.768263</td>\n      <td>57.241669</td>\n      <td>53.594597</td>\n      <td>56.442783</td>\n      <td>38701038.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>GE</td>\n      <td>Industrials</td>\n      <td>0.049742</td>\n      <td>0.043662</td>\n      <td>19.059999</td>\n      <td>-1.324017</td>\n      <td>0.008607</td>\n      <td>2.184394e+09</td>\n      <td>NaN</td>\n      <td>0.051780</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.344084</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.004221</td>\n      <td>0.011810</td>\n      <td>train</td>\n      <td>2010-01-07 00:00:00+00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2010-01-08 00:00:00+00:00</td>\n      <td>56.651195</td>\n      <td>57.971085</td>\n      <td>56.512255</td>\n      <td>57.658478</td>\n      <td>24019636.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>GE</td>\n      <td>Industrials</td>\n      <td>0.017780</td>\n      <td>0.011810</td>\n      <td>18.129999</td>\n      <td>-1.413993</td>\n      <td>-0.564963</td>\n      <td>1.384936e+09</td>\n      <td>NaN</td>\n      <td>0.021539</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.727209</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.003328</td>\n      <td>-0.001118</td>\n      <td>train</td>\n      <td>2010-01-08 00:00:00+00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2010-01-11 00:00:00+00:00</td>\n      <td>58.457350</td>\n      <td>58.631016</td>\n      <td>57.450062</td>\n      <td>58.214211</td>\n      <td>15999249.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>GE</td>\n      <td>Industrials</td>\n      <td>-0.004159</td>\n      <td>-0.001118</td>\n      <td>17.549999</td>\n      <td>-1.465035</td>\n      <td>0.600918</td>\n      <td>9.313836e+08</td>\n      <td>NaN</td>\n      <td>0.009638</td>\n      <td>0.084790</td>\n      <td>NaN</td>\n      <td>1.077109</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.001397</td>\n      <td>0.014180</td>\n      <td>train</td>\n      <td>2010-01-11 00:00:00+00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>437028</th>\n      <td>2018-12-21 00:00:00+00:00</td>\n      <td>18.687380</td>\n      <td>18.954125</td>\n      <td>18.176754</td>\n      <td>18.245346</td>\n      <td>4434600.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>HRB</td>\n      <td>Consumer Cyclical</td>\n      <td>-0.023654</td>\n      <td>0.000825</td>\n      <td>30.110001</td>\n      <td>2.909232</td>\n      <td>-1.809320</td>\n      <td>8.091081e+07</td>\n      <td>7.369267e+07</td>\n      <td>-0.023654</td>\n      <td>-0.112676</td>\n      <td>-0.114645</td>\n      <td>-0.642881</td>\n      <td>0.021191</td>\n      <td>0.021804</td>\n      <td>0.024889</td>\n      <td>0.585</td>\n      <td>-0.020489</td>\n      <td>0.010853</td>\n      <td>test</td>\n      <td>2018-12-21 00:00:00+00:00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>437029</th>\n      <td>2018-12-24 00:00:00+00:00</td>\n      <td>18.169136</td>\n      <td>18.435881</td>\n      <td>17.993847</td>\n      <td>18.009089</td>\n      <td>1678100.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>HRB</td>\n      <td>Consumer Cyclical</td>\n      <td>-0.008809</td>\n      <td>0.010853</td>\n      <td>36.070000</td>\n      <td>3.000000</td>\n      <td>-2.102018</td>\n      <td>3.022105e+07</td>\n      <td>7.425269e+07</td>\n      <td>-0.012949</td>\n      <td>-0.099123</td>\n      <td>-0.152439</td>\n      <td>-0.800662</td>\n      <td>0.020986</td>\n      <td>0.021909</td>\n      <td>0.070188</td>\n      <td>0.640</td>\n      <td>-0.026423</td>\n      <td>0.002186</td>\n      <td>test</td>\n      <td>2018-12-24 00:00:00+00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>437030</th>\n      <td>2018-12-26 00:00:00+00:00</td>\n      <td>18.108161</td>\n      <td>18.961744</td>\n      <td>18.001464</td>\n      <td>18.931259</td>\n      <td>3066300.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>HRB</td>\n      <td>Consumer Cyclical</td>\n      <td>0.045455</td>\n      <td>0.002186</td>\n      <td>30.410000</td>\n      <td>2.812017</td>\n      <td>-1.569047</td>\n      <td>5.804892e+07</td>\n      <td>7.482717e+07</td>\n      <td>0.051206</td>\n      <td>-0.045350</td>\n      <td>-0.105188</td>\n      <td>-0.803862</td>\n      <td>0.024706</td>\n      <td>0.022873</td>\n      <td>0.096820</td>\n      <td>0.695</td>\n      <td>0.050525</td>\n      <td>-0.000705</td>\n      <td>test</td>\n      <td>2018-12-26 00:00:00+00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>437031</th>\n      <td>2018-12-27 00:00:00+00:00</td>\n      <td>18.733111</td>\n      <td>19.152281</td>\n      <td>18.473987</td>\n      <td>19.144661</td>\n      <td>3214400.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>HRB</td>\n      <td>Consumer Cyclical</td>\n      <td>0.021969</td>\n      <td>-0.000705</td>\n      <td>29.959999</td>\n      <td>2.675121</td>\n      <td>-2.376681</td>\n      <td>6.153860e+07</td>\n      <td>7.509515e+07</td>\n      <td>0.011272</td>\n      <td>0.000797</td>\n      <td>-0.104137</td>\n      <td>-0.771849</td>\n      <td>0.024960</td>\n      <td>0.023275</td>\n      <td>0.107925</td>\n      <td>0.700</td>\n      <td>0.007677</td>\n      <td>0.004566</td>\n      <td>test</td>\n      <td>2018-12-27 00:00:00+00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>437032</th>\n      <td>2018-12-28 00:00:00+00:00</td>\n      <td>19.281840</td>\n      <td>19.426644</td>\n      <td>19.045580</td>\n      <td>19.228491</td>\n      <td>2151300.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>HRB</td>\n      <td>Consumer Cyclical</td>\n      <td>-0.002767</td>\n      <td>0.004566</td>\n      <td>28.340000</td>\n      <td>2.320699</td>\n      <td>-2.264180</td>\n      <td>4.136625e+07</td>\n      <td>7.377027e+07</td>\n      <td>0.004379</td>\n      <td>0.028956</td>\n      <td>-0.066593</td>\n      <td>-0.728459</td>\n      <td>0.024501</td>\n      <td>0.023244</td>\n      <td>0.081471</td>\n      <td>0.645</td>\n      <td>-0.001290</td>\n      <td>NaN</td>\n      <td>test</td>\n      <td>2018-12-28 00:00:00+00:00</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>437033 rows Ã— 30 columns</p>\n</div>"},"metadata":{}}],"execution_count":92},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}