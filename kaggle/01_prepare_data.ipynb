{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5549253,"sourceType":"datasetVersion","datasetId":2976522},{"sourceId":13920741,"sourceType":"datasetVersion","datasetId":8870532}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":323.408883,"end_time":"2025-11-30T16:14:55.420951","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-11-30T16:09:32.012068","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"34cd6a0f","cell_type":"code","source":"!rm -rf /kaggle/working/multimodal-eq-sizing\n!git clone https://github.com/brianrp09232000/multimodal-eq-sizing.git /kaggle/working/multimodal-eq-sizing\n!pip install -r /kaggle/working/multimodal-eq-sizing/requirements.txt","metadata":{"papermill":{"duration":10.634715,"end_time":"2025-11-30T16:09:47.413075","exception":false,"start_time":"2025-11-30T16:09:36.778360","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"e0f0f7d7","cell_type":"code","source":"import sys\nimport pathlib\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta","metadata":{"papermill":{"duration":1.871299,"end_time":"2025-11-30T16:09:49.292061","exception":false,"start_time":"2025-11-30T16:09:47.420762","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"15b161b1","cell_type":"code","source":"np.seterr(invalid=\"ignore\")","metadata":{"papermill":{"duration":0.017458,"end_time":"2025-11-30T16:09:49.316772","exception":false,"start_time":"2025-11-30T16:09:49.299314","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"ac5c74fa","cell_type":"code","source":"repo_root = pathlib.Path(\"/kaggle/working/multimodal-eq-sizing\")\nsys.path.append(str(repo_root))","metadata":{"papermill":{"duration":0.01484,"end_time":"2025-11-30T16:09:49.338893","exception":false,"start_time":"2025-11-30T16:09:49.324053","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"9e0557b0","cell_type":"code","source":"from src.data.loaders import (\n    get_tickers_history,\n    get_return_data,\n    get_excess_return,\n    get_vix_data,\n    get_spread_z,\n    get_sector_map,\n    get_adv_dollar\n)","metadata":{"papermill":{"duration":1.011946,"end_time":"2025-11-30T16:09:50.358522","exception":false,"start_time":"2025-11-30T16:09:49.346576","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"c906f54e","cell_type":"markdown","source":"# Find Tickers with the Most Headlines","metadata":{"papermill":{"duration":0.006952,"end_time":"2025-11-30T16:09:50.372674","exception":false,"start_time":"2025-11-30T16:09:50.365722","status":"completed"},"tags":[]}},{"id":"85fcb59e","cell_type":"code","source":"from src.data.universe import tickers_with_most_headlines","metadata":{"papermill":{"duration":0.017689,"end_time":"2025-11-30T16:09:50.397296","exception":false,"start_time":"2025-11-30T16:09:50.379607","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"2d9eb4e3","cell_type":"code","source":"news_df = pd.read_csv(\"/kaggle/input/financial-news/combined.csv\") ","metadata":{"papermill":{"duration":130.542469,"end_time":"2025-11-30T16:12:00.947043","exception":false,"start_time":"2025-11-30T16:09:50.404574","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"01253d8c","cell_type":"code","source":"def count_headlines_per_ticker(news_df, start=None, end=None):\n    \"\"\"Counts the number of headlines for each ticker symbol \n    Input: news_df pandas dataframe with ticker column for ticker symbols\n    Output: pandas dataframe containing two columns: ticker names and the \n                number of headlines for the ticker\"\"\"\n    \n    #check columns in dataframe\n    columns = list(news_df.columns)\n    if (('date' not in columns) and ('Date' not in columns)) or (('ticker' not in columns) and ('Stock_symbol' not in columns)):\n        print('input dataframe does not have both ticker and date columns')\n        return pd.DataFrame()\n    \n    #find column names\n    date_col = 'date' if 'date' in columns else 'Date'\n    ticker_col = 'ticker' if 'ticker' in columns else 'Stock_symbol'\n\n    #filter dates\n    if start is not None: \n        start_filter = news_df[date_col] >= str(start)\n        news_df = news_df[start_filter]\n    if end is not None: \n        end_filter = news_df[date_col] <= str(end)\n        news_df = news_df[end_filter]\n    \n    # Count occurrences in a specific column\n    headline_counts = news_df[ticker_col].value_counts()\n    df = headline_counts.to_frame(name='count')\n    df['ticker'] = list(df.index)\n    df = df.reset_index(drop=True)\n    \n    return df[['ticker','count']]\n\n\n\ndef tickers_with_most_headlines(news_df, start=None, end=None, n=200):\n    \"\"\"Finds the tickers with the most headlines \n    Input: news_df pandas dataframe with ticker column for ticker symbols\n            optional: n interger, number of top tickers to return\n    Output: list containing the number of headlines per ticker\n                for the tickers with the most headlines\"\"\"\n    \n    #count headlines for each ticker\n    df = count_headlines_per_ticker(news_df, start, end)\n\n    #limit dataframe to n tickers\n    df = df.sort_values(['count'], ascending=False)\n    df = df[:n]\n    df.reset_index(drop=True, inplace=True)\n    \n    return df","metadata":{"papermill":{"duration":0.019277,"end_time":"2025-11-30T16:12:00.973688","exception":false,"start_time":"2025-11-30T16:12:00.954411","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"fc49ca87","cell_type":"code","source":"start = pd.Timestamp('2010-01-04 05:00:00+0000', tz='UTC')\nend   = pd.Timestamp('2018-12-28 05:00:00+0000', tz='UTC')\ntickers = tickers_with_most_headlines(news_df, str(start), str(end), 300)","metadata":{"papermill":{"duration":5.362077,"end_time":"2025-11-30T16:12:06.342974","exception":false,"start_time":"2025-11-30T16:12:00.980897","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"ba719fef","cell_type":"markdown","source":"# Get Price Data","metadata":{"papermill":{"duration":0.007127,"end_time":"2025-11-30T16:12:06.357353","exception":false,"start_time":"2025-11-30T16:12:06.350226","status":"completed"},"tags":[]}},{"id":"546a9699","cell_type":"code","source":"#get yfinance ticker history for all tickers in tickers df\n#yfinance will produce the \"possibly delisted\" message for tickers without information\ndf = get_tickers_history(list(tickers['ticker']), start=start, end=end)","metadata":{"papermill":{"duration":69.169906,"end_time":"2025-11-30T16:13:15.534531","exception":false,"start_time":"2025-11-30T16:12:06.364625","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"b21c0074","cell_type":"code","source":"#limit df to only 200 tickers and tickers with data\nkeep_tickers = list(df['ticker'].drop_duplicates()[:200])\ndf = df[df['ticker'].isin(keep_tickers)]\ntickers = tickers[tickers['ticker'].isin(keep_tickers)]","metadata":{"papermill":{"duration":0.06803,"end_time":"2025-11-30T16:13:15.666774","exception":false,"start_time":"2025-11-30T16:13:15.598744","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"c6a02e2c","cell_type":"code","source":"def get_date_range(df: pd.DataFrame) -> tuple:\n    grouped_by_date = df.groupby([\"ticker\"]).agg(['min', 'max', 'count'])[\"Date\"]\n    start = grouped_by_date[\"min\"].min()\n    end = grouped_by_date[\"max\"].max()\n    return start, end","metadata":{"papermill":{"duration":0.01969,"end_time":"2025-11-30T16:13:15.697778","exception":false,"start_time":"2025-11-30T16:13:15.678088","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"794d9f4c","cell_type":"code","source":"#df = get_return_data(\"/kaggle/input/news-trading/return_data.csv\")\n#start, end = get_date_range(df)","metadata":{"papermill":{"duration":0.01814,"end_time":"2025-11-30T16:13:15.727273","exception":false,"start_time":"2025-11-30T16:13:15.709133","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"c088f97f","cell_type":"markdown","source":"# Add excess return","metadata":{"papermill":{"duration":0.011281,"end_time":"2025-11-30T16:13:15.750071","exception":false,"start_time":"2025-11-30T16:13:15.738790","status":"completed"},"tags":[]}},{"id":"3fe96ef2","cell_type":"code","source":"def add_excess_return(df, start, end):\n    excess_return_df = get_excess_return(df, start, end)\n    df = df.merge(excess_return_df, on=[\"ticker\", \"Date\"], how=\"left\")\n    return df","metadata":{"papermill":{"duration":0.019455,"end_time":"2025-11-30T16:13:15.780750","exception":false,"start_time":"2025-11-30T16:13:15.761295","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"824a80ea","cell_type":"code","source":"df = add_excess_return(df, start, end)","metadata":{"papermill":{"duration":0.531973,"end_time":"2025-11-30T16:13:16.324203","exception":false,"start_time":"2025-11-30T16:13:15.792230","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"afd6242b","cell_type":"markdown","source":"# Add market regime VIX z-score","metadata":{"papermill":{"duration":0.01161,"end_time":"2025-11-30T16:13:16.347237","exception":false,"start_time":"2025-11-30T16:13:16.335627","status":"completed"},"tags":[]}},{"id":"a7cbe413","cell_type":"code","source":"def add_vix_z(df, start, end):\n    vix_z_df = get_vix_data(start, end)\n    format_str = \"%Y-%m-%d\"\n    vix_z_df[\"Date\"] = vix_z_df[\"Date\"].dt.strftime(format_str)\n    df[\"Date\"] = df[\"Date\"].dt.strftime(format_str) \n    df = df.merge(vix_z_df, on=[\"Date\"], how=\"left\")\n    df['Date'] = pd.to_datetime(df['Date'], utc=True)\n    return df","metadata":{"papermill":{"duration":0.019934,"end_time":"2025-11-30T16:13:16.378650","exception":false,"start_time":"2025-11-30T16:13:16.358716","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"c7012117","cell_type":"code","source":"df = add_vix_z(df, start, end)","metadata":{"papermill":{"duration":3.739832,"end_time":"2025-11-30T16:13:20.129838","exception":false,"start_time":"2025-11-30T16:13:16.390006","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"7e5e18ef","cell_type":"markdown","source":"# Add spread z-score","metadata":{"papermill":{"duration":0.012449,"end_time":"2025-11-30T16:13:20.154713","exception":false,"start_time":"2025-11-30T16:13:20.142264","status":"completed"},"tags":[]}},{"id":"5ea6ce20","cell_type":"code","source":"def add_spread_z(existing_df: pd.DataFrame, buffer_days=380) -> pd.DataFrame:\n    \"\"\"\n    Use existing OHLCV df, pull buffered history, compute young-safe spread_z on the combined\n    Then merge back only the target window rows to prevent nulls.\n    \"\"\"\n    df = existing_df.copy()\n    start, end = df[\"Date\"].min(), df[\"Date\"].max()\n\n    tickers = sorted(df['ticker'].unique())\n    fetch_start = start - timedelta(days=buffer_days)\n    fetch_end   = end\n\n    # You already have get_tickers_history(tickers, start, end)\n    hist = get_tickers_history(tickers, fetch_start, fetch_end)\n    hist[\"Date\"] = pd.to_datetime(hist[\"Date\"], utc=True)\n\n    # Combine buffer + existing; keep existing rows on overlap\n    combined = pd.concat([hist, df], ignore_index=True)\n    combined = combined.sort_values(['ticker', \"Date\"])\n    combined = combined.drop_duplicates(subset=['ticker', \"Date\"], keep=\"last\")\n\n    # Compute young-safe spread_z on the full combined range\n    combined = get_spread_z(combined)\n\n    # Merge only computed columns back to target window\n    cols_to_merge = ['ticker', 'Date', \"spread_z\"]\n    out = df.merge(combined[cols_to_merge], on=['ticker', 'Date'], how=\"left\")\n\n    # Final minimal, causal clean-up to guarantee NON-NULL spread_z in target window:\n    # 1) per-ticker forward-fill (past only), 2) same-day cross-section median, 3) final 0\n    out[\"spread_z\"] = (\n        out.groupby('ticker')[\"spread_z\"].ffill()\n           .fillna(out.groupby('Date')[\"spread_z\"].transform(\"median\"))\n           .fillna(0.0)\n    ).clip(-3, 3)\n\n    return out","metadata":{"papermill":{"duration":0.023693,"end_time":"2025-11-30T16:13:20.190150","exception":false,"start_time":"2025-11-30T16:13:20.166457","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"05f3ed70","cell_type":"code","source":"df = add_spread_z(df)","metadata":{"papermill":{"duration":35.467227,"end_time":"2025-11-30T16:13:55.669736","exception":false,"start_time":"2025-11-30T16:13:20.202509","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"65999dc0","cell_type":"markdown","source":"# Add sector","metadata":{"papermill":{"duration":0.011368,"end_time":"2025-11-30T16:13:55.693155","exception":false,"start_time":"2025-11-30T16:13:55.681787","status":"completed"},"tags":[]}},{"id":"5f2b2e96","cell_type":"code","source":"def add_sector(df):\n    tickers = df[\"ticker\"].unique()\n    sector_map = get_sector_map(tickers)\n    df = df.join(sector_map, on=\"ticker\")\n    return df","metadata":{"papermill":{"duration":0.01936,"end_time":"2025-11-30T16:13:55.723845","exception":false,"start_time":"2025-11-30T16:13:55.704485","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"58abed12","cell_type":"code","source":"df = add_sector(df)","metadata":{"papermill":{"duration":41.427046,"end_time":"2025-11-30T16:14:37.162730","exception":false,"start_time":"2025-11-30T16:13:55.735684","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"f5cad76d","cell_type":"markdown","source":"# Add dollar-volume ADV ","metadata":{"papermill":{"duration":0.01126,"end_time":"2025-11-30T16:14:37.185745","exception":false,"start_time":"2025-11-30T16:14:37.174485","status":"completed"},"tags":[]}},{"id":"f1c342f3","cell_type":"code","source":"def add_adv_dollar(df):\n    adv_df = get_adv_dollar(df)\n    \n    df = df.merge(\n        adv_df,\n        on=[\"Date\", \"ticker\"],\n        how=\"left\",\n    )\n    return df","metadata":{"papermill":{"duration":0.018872,"end_time":"2025-11-30T16:14:37.215923","exception":false,"start_time":"2025-11-30T16:14:37.197051","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"5c37a201","cell_type":"code","source":"df = add_adv_dollar(df)","metadata":{"papermill":{"duration":0.406962,"end_time":"2025-11-30T16:14:37.634346","exception":false,"start_time":"2025-11-30T16:14:37.227384","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"92b272ea-1b98-4a00-9b4c-aa794aae1eb9","cell_type":"markdown","source":"# Add Next Day Excess","metadata":{}},{"id":"0bdcf5dc-af5f-4508-87a0-444e9077bf24","cell_type":"code","source":"df[\"next_day_excess_return\"] = df.groupby('ticker')['excess_return'].shift(-1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e5c3fe14-3dca-47df-90d3-4d48aa8f605f","cell_type":"code","source":"df_org = df.copy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"213f55af-da3c-4813-9fee-c86a7f7a0973","cell_type":"code","source":"df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"23a926e5-21fe-4357-8f86-b11cc5109cd7","cell_type":"markdown","source":"# Add News Flag","metadata":{}},{"id":"3665c1a0-9918-4342-9090-7d409ed2d01a","cell_type":"code","source":"from src.data.features.news_features import count_headlines_all_days\n\n\ndef add_news_flag(news_df, price_df, start=None, end=None):\n    \"\"\"adds a new news flag column: 0=no news, 1=news\n    input: news_df with 'date', 'ticker', and other columns\n            price_df with 'Date', 'ticker', and other columns\n            optional start and end Timestamps\n    output: dataframe df\n    \"\"\"\n\n    #count headlines per ticker per day\n    news_count = count_headlines_all_days(news_df)\n\n    #filter count_df by date\n    news_count = news_count.T\n    news_count['date'] = pd.to_datetime(list(news_count.index), utc=True)\n    if start is not None: news_count = news_count[news_count['date'] >= start]\n    if end is not None: news_count = news_count[news_count['date'] <= end]\n    \n    #convert news_count df to different format\n    news_cols = list(news_count.columns)\n    news_count = news_count.melt(id_vars=['date'], value_vars=news_cols, \n                  var_name='ticker', value_name='news flag')\n\n    # change count to flag: 0=no news, 1=news\n    news_count['news flag'] = [flag if flag < 2 else 1 for flag in news_count['news flag']]\n    news_count['date'] = pd.to_datetime(news_count['date'], utc=True)\n    news_count.sort_values(['date','ticker'], inplace=True)\n    \n    #add news flag: 0=no news, 1=news\n    price_df = pd.merge(price_df, news_count, left_on=['Date','ticker'], \n              right_on=['date','ticker'])\n\n    return price_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1ebfe854-7fb9-4bb9-b321-dce85a15182f","cell_type":"code","source":"df = add_news_flag(news_df, df, start=start, end=end)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4c360cae-c0b8-4bd4-a142-53ff261da2ca","cell_type":"markdown","source":"# Split Data","metadata":{}},{"id":"3cf5de46-1c8a-4979-ba91-4d5469f06ffe","cell_type":"code","source":"df['split'] = 'train'\ndf.loc[df['Date'] >=\"2015-01-01\", \"split\"] = \"val\"\ndf.loc[df['Date'] >= \"2017-01-01\", \"split\"] = 'test'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c28cdb24","cell_type":"markdown","source":"# Final Complete Dataset","metadata":{"papermill":{"duration":0.011232,"end_time":"2025-11-30T16:14:37.657197","exception":false,"start_time":"2025-11-30T16:14:37.645965","status":"completed"},"tags":[]}},{"id":"013a1361","cell_type":"code","source":"df.to_csv('final_dataset.csv', index=False)","metadata":{"papermill":{"duration":12.169707,"end_time":"2025-11-30T16:14:49.838204","exception":false,"start_time":"2025-11-30T16:14:37.668497","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"7e364950","cell_type":"code","source":"tickers.to_csv('top_tickers.csv', index=False)","metadata":{"papermill":{"duration":0.020997,"end_time":"2025-11-30T16:14:49.870950","exception":false,"start_time":"2025-11-30T16:14:49.849953","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"cb3f672a","cell_type":"code","source":"get_return_data(\"/kaggle/working/final_dataset.csv\")","metadata":{"papermill":{"duration":2.16567,"end_time":"2025-11-30T16:14:52.048487","exception":false,"start_time":"2025-11-30T16:14:49.882817","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"968d02ac","cell_type":"code","source":"!rm -rf /kaggle/working/multimodal-eq-sizing","metadata":{"papermill":{"duration":0.423442,"end_time":"2025-11-30T16:14:52.485232","exception":false,"start_time":"2025-11-30T16:14:52.061790","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}